\documentclass[11pt]{article}
\usepackage{a4wide,parskip}
\usepackage{hyperref}
\usepackage{titlesec}

\titleformat{\section}{\normalfont\fontsize{12}{15}\bfseries}{\thesection}{1em}{}

\begin{document}

\centerline{\Large R209 Essay:  Adversarial reasoning}
\vspace{2em}
\centerline{\large Chongyang Shi (\emph{cs940})}
\vspace{1em}
\centerline{\large \today}
\vspace{1em}

This essay provides a synthesis of three papers from distinct eras of computing. Adversarial reasoning, a process of applying computational approaches to inferring and anticipating an enemy's perceptions, intents and actions \cite{kott2015toward}, was applied to three very different systems: an early mainframe Multics system in the 1970s \cite{karger1974multics}, a modern computerised car \cite{koscher2010experimental}, and virtual machines running on a hypervisor server \cite{razavi2016flip}.

\section{Summaries of research}

Research by Karger and Schell \cite{karger1974multics} was a comprehensive vulnerability analysis of the Multics mainframe system, one of the first to implement multi-level security at the time. Karger and Schell discovered that despite a sound specification of security control \cite[3.1]{karger1974multics}, non-conformance \cite[3.2.1]{karger1974multics} or even optimisation attempts \cite[3.3.2]{karger1974multics} in hardware and software implementations have introduced vulnerabilities into the system. These vulnerabilities allow a perpetrator to access unauthorised information, insert trap doors, or deny system use by causing crash, while being able to modify audit trails to avoid detection \cite[3.4.4]{karger1974multics}. The cost of discovering the vulnerabilities was low \cite[Tb. 3]{karger1974multics}. Possibilities of security compromise during the development and servicing of the system were also identified. Recommendations were made towards making Multics more secure.

Research by Koscher et. al. \cite{koscher2010experimental} studied the scale of vulnerabilities of modern vehicles with computerised control. Both laboratory and field tests were conducted to demonstrate the grave possible compromises on vehicle safety, as a result of weak security requirements in system standards \cite[IV. B.]{koscher2010experimental} as well as further non-compliant implementation of security deviating from standards \cite[IV. C.]{koscher2010experimental}. It was discovered that almost all compliant security features could be bypassed through brute force attacks \cite[IV. B.]{koscher2010experimental} or reverse engineering \cite[V. A.]{koscher2010experimental}. Researchers were able to produce a wide range of dangerous vehicle behaviours through the vulnerabilities. Concerns on economical and legal aspects of vehicle security were discussed.

Razavi et. al. \cite{razavi2016flip} developed a hardware-based attack on software security systems such as RSA, through the use of shared physical memory on hypervisor environments. Combined software and hardware attacks were deployed by exploiting Linux memory optimisation features and intentionally inducing memory errors. Under ideal conditions it is possible to weaken and defeat public key securities with strengths currently considered as secure \cite[Sec. 5]{razavi2016flip}. Both hardware and software mitigations to the attack developed were discussed. The attack however requires very specific conditions to work, namely a high-memory VM \cite[Fig. 4]{razavi2016flip} running on the same hypervisor as the victim, with KSM and THP turned on \cite[4.3.1]{razavi2016flip}, on specific hardware \cite[6.1.1]{razavi2016flip}, along with a notable chance to fail \cite[5.2]{razavi2016flip}. Therefore, a survey on the size of potential victims could help assessing the practicalness of this attack.

\section{Key themes of research}

\subsection{Was adversarial reasoning applied at all during the design of systems?}

For some system designers, adversarial reasoning is a key part of the design process. While in other cases, it may not have been considered at all, often with disastrous consequences. An example of adversarial reasoning can be seen in the specification of Multics \cite[3.1]{karger1974multics}. Unfortunately, errors in both hardware and software implementation \cite[3.2.2, 3.3.1]{karger1974multics} resulted in the vulnerabilities identified by the authors. This demonstrates the need to apply adversarial reasoning on both the specification and the implementation of a system. 

On the two more recent systems studied, adversarial reasoning was either absent or based on a more restrictive threat model. The vehicle control system studied by Koscher et. al. \cite{koscher2010experimental} lacked protection against short or well-hidden physical access to the intra-vehicle network, adding to the fact that implemented security features are relatively easy to compromise \cite[IV. B.]{koscher2010experimental}. Software security systems on platforms attacked by Razavi et. al. \cite{razavi2016flip} were not resistant against memory-based attacks, despite the fact that integrity verification could have mitigated the issues without altering the underlying hardware \cite[6.2]{razavi2016flip}.

\subsection{Bypassing software security through hardware attacks}

It was demonstrated in all three papers that by compromising the underlying hardware, a software system can be significantly weakened in security. Address check bypass in Multics was made possible by an error in hardware implementation \cite[3.2.2]{karger1974multics}. Design flaws such as broadcast of all packets allowed circumvention of challenge-response features in issuing unsafe commands to car components \cite[V. B.]{koscher2010experimental}. While the downsizing of DRAM modules gave realistic possibilities to Rowhammer attacks on physical memory \cite[6.2]{razavi2016flip}, thus weakening software cryptography systems. Hardware has become a significant point of entry for unconventional attacks to occur.

\subsection{Performance and economic constraints could compromise security}

Due to the desire to improve performance or the need to make designs more economical, vulnerabilities were introduced into the systems studied by the three papers. In Multics, software optimisations made to speed up fault processing introduced a privilege escalation exploit \cite[3.3.2]{karger1974multics}. In computerised vehicle control, weak security of commonly used CAN bus can be partly attributed to economic pressure on design \cite[II. A.]{koscher2010experimental}. And in Linux hypervisors, default-on features for memory performance optimisation such as KSM and THP made the attack by \cite{razavi2016flip} possible. The high cost nature of error-correcting memory also increased the number of vulnerable systems \cite[6.1.1]{razavi2016flip}.

\section{Ideas of current context}

Due to the large time gap between the study on Multics \cite{karger1974multics} and the two later studies \cite{koscher2010experimental}\cite{razavi2016flip}, two ideas from the Multics study were reflected very differently in the later studies.

The ability for a perpetrator to completely erase the audit trail of his attack was as much possible in 1970s \cite[3.4.4]{karger1974multics} as in 2010s \cite[VI. C.]{koscher2010experimental}. The method to achieve this was also largely the same: deleting records through privilege escalation. The lack of an audit trail can make detection and investigation of intrusions difficult or impossible. In order to protect audit trails in the case of an intrusion, recent designs and researches focus on temper-resistant hardware audit systems either hardcoded in the processor \cite{bordsen1993cache} or securely tied to the system \cite{chong2003secure}.

Karger and Schell considered physical memory exploits impractical, due to the little or no control users exercise on hardware. However, in modern computer systems, this has become possible due to unintended consequences of memory optimisation techniques as well as downsizing of memory modules, as applied by Razavi et. al. \cite{razavi2016flip}. Similar attacks under modern memory systems are now common, such as one utilised earlier by Govindavajhala and Appel \cite{govindavajhala2003using} against Java virtual machines.

Another general observation made by Karger and Schell \cite[3.3.1]{karger1974multics} remains largely accurate to this day: while it is often possible to prove the security of a security concept or protocol, implementations of such often introduce vulnerabilities into the system, making security assurances impossible. The presence of users can also compromise the security of a system \cite{adams1999users}. Most current security researches concentrate on verifying the security of a protocol, rather than the security of an implemented system such as Multics, as the former is inevitably easier to approach.

\section{Literature review}

\bibliographystyle{IEEEtran}
\footnotesize{\bibliography{week2}}


\end{document}
